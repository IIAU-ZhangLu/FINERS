<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FINERS</title>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css"/>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css"/>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        .section {
            max-width: 1000px;
            margin-bottom: 20px;
            margin: 0 auto 20px;
            border: 1px solid #ddd; /* 边框 */
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 0 16px rgba(0, 0, 0, 0.3);
        }
        header {
            text-align: center;
            margin-bottom: 20px;
        }
        header h1 {
            font-weight:100;
            margin: 10px 0;
            font-size: 28px;
        }
        .logo {
            font-weight: 900;
            font-style:italic;
            font-size: 40px;
            margin-bottom: 5px;
        }
	.gradient-title{
	    background:linear-gradient(to right,#ff0000,#9900ff);
	    -webkit-background-clip:text;
	    background-clip:text;
	    -webkit-text-fill-color:transparent;
	    text-fill-color:transparent;
	    text-align:center;
	    font-size:36px;
	    font-weight:600;
	}
	.conference{
	    text-align:center;
            font-size:26px;
            font-weight:700;
            color: #000;
            margin:10px;
	}
        .authors {
            text-align: center;
            margin-bottom: 15px;
            font-size: 15px;
            display:flex;
            flex-direction:column;
            align-items:center;
            gap:10px;
        }
        .authors a{
            color: #0066cc;
            text-decoration:none;
        }
	.authors-row{
            display:flex;
	    gap:30px;
	}
	.email-sup {
    		vertical-align: super; /* 使✉以上标形式显示 */
    		font-size: 0.7em; /* 调整✉的大小，使其更协调 */
    		margin-left: 2px; /* 调整✉与作者名称的间距 */
	}
        .institutions {
            display:flex;
	    flex-direction:row;
	    flex-wrap:wrap;
	    justify-content:center;
            text-align: center;
            margin-bottom: 15px;
            font-size: 13px;
	    gap:10px;
        }
        .institutions-row{
	    display:flex;
            width:100%;
            justify-content: center;
	    gap:50px;
	}
        .badges {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 30px;
        }
        .badge {
            padding: 5px 10px;
            background-color: #2b2d31;
            color: #fff;
            border-radius: 20px;
            font-size: 16px;
            text-decoration: none;
            transition:background-color 0.3s ease;
        }
	.badge:hover{
	    background-color: #4a4c50;
	}
        .experiment {
            margin: 0 auto;
	    max-width:1200px;
            margin-bottom: 20px;
	    padding-top:40px;
	    padding-bottom:30px;
        }
        .experiment-black{
            color:#4B0082;
            font-weight:700;
            font-size:24px;
	    text-align:center;
	    display:block;
        }
        .experiment-green{
            color:#4CAF50;
            font-weight:700;
            font-size:24px;
	    text-align:center;
	    display:block;
	    margin-bottom:12px;
        }
	.experiment img{
	    max-width:100%;
	    height:auto;
	    margin-top:20px;
	    margin-bottom:20px;
	}
	.experiment-desc{
	    text-align:left;
	    font-size:18px;
	    line-height:1.5;
	    margin:0 auto;
	    max-width:1200px;
	}
	.overview {
            text-align: center;
            margin-bottom: 20px;
	    padding-top:40px;
	    padding-bottom:30px;
        }
        .overview-black{
            color:black;
            font-weight:700;
            font-size:20px;
        }
	.overview img{
	    max-width:100%;
	    height:auto;
	    margin-top:20px;
	}
        .comparsion {
            text-align: center;
            margin-bottom: 20px;
	    padding-top:40px;
	    padding-bottom:30px;
        }
        .comparsion-black{
            color:black;
            font-weight:700;
            font-size:24px;
        }
	.comparsion img{
	    max-width:100%;
	    height:auto;
	    margin-top:20px;
	}
	.visual-results{
	    max-width:1200px;
	    margin:0 auto;
	    padding:40px 20px;
	}
	.visual-results h3{
	    text-align:center;
	    margin-bottom:20px;
	    font-size:24px;
	    font-weight:700;
	    color:#990000;
	}
	.visual-results-desc{
	    text-align:left;
	    font-size:18px;
	    line-height:1.5;
	    margin:0 auto;
	    max-width:1200px;
	}
	.highlight-term{
	    font-weight:bold;
	    color:black;
	}
        .image-container {
	    max-width:none;
            display:flex;
	    flex-wrap:wrap;
            gap: 20px;
            margin: 0 auto;
        }
        .image-container img {
            max-width:100%;
            border-radius: 4px;
	    height:auto;
        }
    /* 箭头样式（保持一致） */
    .slick-prev, .slick-next {
      background-color: rgba(0, 0, 0, 0.5);
      color: white;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      z-index: 10;
    }
    .slick-prev:hover, .slick-next:hover {
      background-color: rgba(0, 0, 0, 0.8);
    }
        .abstract-bg {
	    background-color: #f0f9f5;
	    width:100%;
        }
	.abstract-bg2{
	    background-color:#f5f9ff;
	    width:100%;
	}
        .abstract-content {
	    max-width:820px;
	    margin:0 auto;
	    padding: 20px;
        }
        .abstract-content h2 {
	    font-wight:700;
            text-align: center;
            margin-bottom: 15px;
	    font-size:24px;
	}
	.abstract-content p{
	    font-size:18px;
	    line-height:1.6;
	    text-align:justify;
	}
	.citation{
	    padding:20px;
	    overflow-x:auto;
	    margin:0;
	    font-size:18px;
	    max-width:1000px;
	}

    /* 上方效果图轮播容器 */
    .preview-carousel {
      max-width: 1200px;
      margin: 0 auto 40px;
      height: 600px; /* 固定轮播高度，确保效果图显示整齐 */
    }
    .preview-carousel img {
      width: 100%;
      height: 100%;
      object-fit: cover; /* 保持图片比例，填充容器 */
    }

    /* 下方原图轮播容器 */
    .original-carousel-container {
      max-width: 1160px;
      margin: 0 auto;
      background-color:#e6e6fa;
      border:1px solid #ccc;
      padding:20px;
    }
    .original-carousel img {
      width: 280px;
      height: 180px;
      object-fit:cover;
      margin: 0 10px;
      cursor: pointer;
      border: 2px solid #ddd;
      border-radius: 4px;
      transition: all 0.3s ease;
    }
    .original-carousel img:hover {
      transform: scale(1.05);
      border-color: #666;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }
    </style>
</head>
<body>

        <header>
            <div class="logo">FINERS</div>
            <h1 class="gradient-title">Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning</h1>
	    <div class="conference">(NeurIPS 2025)</div>
        </header>
        <div class="authors">
		<div class="authors-row">
			<a href="https://scholar.google.com.hk/citations?user=bUtRE5UAAAAJ&hl=zh-CN">Lu Zhang<sup>1*</sup></a>
    	        	<a href="https://scholar.google.com.hk/citations?user=FPoIE0UAAAAJ&hl=zh-CN">Jiazuo Yu<sup>1</sup></a>
    			<a href="https://scholar.google.com.hk/citations?user=vtz2hQ8AAAAJ&hl=zh-CN">Haomiao Xiong<sup>1</sup></a>
    			<a href="https://scholar.google.com.hk/citations?user=ddrD2TgAAAAJ&hl=zh-CN">Ping Hu<sup>2</sup></a>
		</div>
		<div class="authors-row">
    			<a href="https://scholar.google.com.hk/citations?user=-37EfvgAAAAJ&hl=zh-CN">Yunzhi Zhuge<sup>1</sup></a>
    			<a href="https://scholar.google.com.hk/citations?user=D3nE0agAAAAJ&hl=zh-CN">Huchuan Lu<sup>1</sup></a>
    			<a href="https://www.sigs.tsinghua.edu.cn/heyou/main.htm">You He<sup>3</sup></a>
		</div>
	</div>
        <div class="institutions">
		<div class="institutions-row">
            		<span>¹Dalian University of Technology </span>
            		<span>²University of Electronic Science and Technology of China</span>
		</div>
		<div class="institutions-row">
            		<span>³Tsinghua Shenzhen International Graduate School</span>
		</div>

        </div>
        <div class="badges">
            <a href="https://cocodataset.org/#home" class="badge">Dataset</a>
            <a href="https://arxiv.org/abs/2502.08639" class="badge">Paper</a>
            <a href="https://github.com/Zheng-Chong/CatV2TON" class="badge">Code</a>
        </div>
        <div class="abstract-bg">
	  <div class="abstract-content">
            <h2>Abstract</h2>
            <p>Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities across a wide range of vision-language tasks. However, due to the restricted input resolutions, MLLMs face significant challenges in precisely understanding and localizing visual details in high-resolution images—particularly when dealing with extra-small objects embedded in cluttered contexts. To address this issue, we propose FINERS, a two-stage MLLM-based reinforcement learning framework for jointly reasoning and segmenting extremely small objects within high-resolution scenes. FINERS adopts a coarse-to-fine pipeline comprising Global Semantic Exploration (GSE) and Localized Perceptual Refinement (LPR). Specifically, GSE performs instruction-guided reasoning to generate a textural response and a coarse target region, while LPR refines this region to produce an accurate bounding box and segmentation mask. To couple the two stages, we introduce a locate-informed retrospective reward, where LPR’s outputs are used to optimize GSE for more robust coarse region exploration. Additionally, we present FINERS-4k, a new dataset for evaluating MLLMs on attribute-level reasoning and pixel-level segmentation on subtle, small-scale targets in complex high-resolution scenes. Experimental results on FINERS-4k and public datasets demonstrate that our method consistently outperforms state-of-the-art MLLM-based approaches on both instruction-guided segmentation and visual reasoning tasks.</p>
	  </div>
        </div>
	<div class="visual-results">
		<h3>Visual Results of small targets detection</h3>
		<div class="image-container slick-carousel">
                	<img src="Image/MVQA.png"alt="实验相关图片">
                	<img src="Image/OVQA.png" alt="实验相关图片">
                	<img src="Image/IS.png"alt="实验相关图片">
		</div>
		<p class="visual-results-desc">
		Visual results on Open-ended VQA (<span class="highlight-term">OVQA</span>), 
		Multiple-choice VQA (<span class="highlight-term">MVQA</span>), 
		and Instruction-guided Segmentation (<span class="highlight-term">IS</span>). 
		The listed images are sampled from <span class="highlight-term">FINERS-4k</span> test set.
		</p>
	</div>
	<div class="experiment">
		<h2 class="experiment-black">Overview of our Benchmark</h2>
		<img src="Image/benchmark.png" alt="Benchmark的相关图片">
		<p class="experiment-desc">(a) The innermost ring shows three instruction types. The middle ring presents the mask size distribution within each type. The outermost ring breaks each type down into four attribute categories: color, shape, position, and others. (b) Visualization of six representative examples, each illustrating a different attribute category (color, shape, position, others) across the three instruction types in the outermost ring.</p>
        </div>

  <h2 style="text-align:center;margin:20px 0;">Visual Examples from Our Instruction-based Small Object Segmentation Datasets</h2>
  <p style="text-align:center;margin-bottom: 20px;">Results is generated using <a href="#" style="color:#007bff;">FINERS</a>.</p>
  <!-- 上方：效果图轮播（初始隐藏或显示第一张） -->
  <div class="preview-carousel">
    <img src="Image/re-1.jpg" alt="Preview 1">
    <img src="Image/re-2.jpg" alt="Preview 2">
    <img src="Image/re-3.jpg" alt="Preview 3">
    <img src="Image/re-4.jpg" alt="Preview 4">
    <img src="Image/re-5.jpg" alt="Preview 5">
    <img src="Image/re-6.jpg" alt="Preview 6">
    <img src="Image/re-7.jpg" alt="Preview 7">
    <img src="Image/re-8.jpg" alt="Preview 8">
  </div>

  <!-- 下方：原图轮播 -->
  <div class="original-carousel-container">
    <div class="original-carousel">
      <img src="Image/1.jpg" alt="Original 1" data-preview-index="0">
      <img src="Image/2.jpg" alt="Original 1" data-preview-index="1">
      <img src="Image/3.jpg" alt="Original 1" data-preview-index="2">
      <img src="Image/4.jpg" alt="Original 1" data-preview-index="3">
      <img src="Image/5.jpg" alt="Original 1" data-preview-index="4">
      <img src="Image/6.jpg" alt="Original 1" data-preview-index="5">
      <img src="Image/7.jpg" alt="Original 1" data-preview-index="6">
      <img src="Image/8.jpg" alt="Original 1" data-preview-index="7">
    </div>
  </div>

	<div class="experiment">
		<h2 class="experiment-green">Overview of our framework</h2>
		<img src="Image/framework.png" alt="Benchmark的相关图片">
		<p class="experiment-desc">(a) During training, we design specific reward functions to train GSE and LPR, where the LPR is optimized first and adopted to form a retrospective reward to enhance the coarse region accuracy of GSE. (b) During inference, GSE takes a high-resolution image and user instructions as input and produces an answer and a coarse region containing referred objects. Then, LPR processes the instruction and coarse region to generate the object box and adopts SAM2 to generate the final mask. (c) To unify VQA and segmentation into a single MLLM, we design a multi-task reward pool and assign the items to supervise GSE and LPR.</p>
        </div>



        <div class="abstract-bg2">
	  <div class="abstract-content">
            <h2>Citation</h2>
            <pre class="citation"     >
	@article{zhang2025,
        title={Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning},
        author={Zhang, Lu and Yu, Jiazuo and Xiong, Haomiao and Hu, Ping and Zhuge, Yunzhi and Lu, Huchuan and He, You},
        year={2025}
	}
	    </pre>
	  </div>
        </div>
   <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
   <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>
   <script>
   $(document).ready(function(){
  	// 可视化结果轮播
  	$('.slick-carousel').slick({
    		arrows: true, // 显示左右箭头
    		dots: true, // 显示圆点导航
    		infinite: true, // 无限循环（滑到最后一张可回到第一张）
    		speed: 500, // 滑动动画速度（毫秒）
    		slidesToShow: 1, // 每次显示 1 张图片
    		slidesToScroll: 1, // 每次滑动 1 张图片
    		autoplay: true, // 自动播放（如需自动，设为 true）
    		autoplaySpeed: 2000, // 自动播放间隔（毫秒，autoplay 为 true 时生效）
 	 });
  // 上方“效果图轮播”
  const previewCarousel = $('.preview-carousel').slick({
    dots: false,
    arrows: false,
    infinite: true,
    speed: 300,
    autoplay: true, // 自动播放
    autoplaySpeed: 2000, // 自动播放间隔
    slidesToShow: 1, // 一页仅显示 1 张效果图
    slidesToScroll: 1
  });

  // 下方“原图轮播”
  const originalCarousel = $('.original-carousel').slick({
    dots: false,
    arrows: true,
    infinite: true,
    speed: 300,
    slidesToShow: 5, 
    slidesToScroll: 1
  });

  // 3. 点击原图 → 上方效果图轮播跳转到对应索引
  $('.original-carousel img').on('click', function() {
    const previewIndex = $(this).data('preview-index'); // 获取效果图对应索引
    previewCarousel.slick('slickGoTo', previewIndex); // 跳转到指定效果图
  });
});
   </script>
</body>
</html>